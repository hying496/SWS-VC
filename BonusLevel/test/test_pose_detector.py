# test_pose_detector.py
# å®Œæ•´æµ‹è¯•pose_detectoræ¨¡å—

import cv2
import numpy as np
import sys
import os
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„ - ä»testæ–‡ä»¶å¤¹å¯¼å…¥ä¸Šçº§ç›®å½•çš„æ¨¡å—
project_root = Path(__file__).parent.parent  # Bonus Level ç›®å½•
sys.path.insert(0, str(project_root))
print(f"ğŸ” é¡¹ç›®æ ¹ç›®å½•: {project_root}")

try:
    from detector.pose_detector import (
        PoseDetectionManager,
        DetectorType,
        DetectorFactory
    )

    print("âœ… æˆåŠŸå¯¼å…¥pose_detectoræ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ï¼š")
    print("1. detector/pose_detector.py æ–‡ä»¶å­˜åœ¨")
    print("2. detector/__init__.py æ–‡ä»¶å­˜åœ¨ï¼ˆå¯ä»¥æ˜¯ç©ºæ–‡ä»¶ï¼‰")
    sys.exit(1)


class PoseDetectorTester:
    """å§¿æ€æ£€æµ‹å™¨æµ‹è¯•ç±»"""

    def __init__(self):
        self.test_results = {}
        print("ğŸ§ª å§¿æ€æ£€æµ‹å™¨æµ‹è¯•å™¨åˆå§‹åŒ–")

    def test_1_basic_import(self):
        """æµ‹è¯•1: åŸºç¡€å¯¼å…¥æµ‹è¯•"""
        print("\n" + "=" * 50)
        print("ğŸ§ª æµ‹è¯•1: åŸºç¡€å¯¼å…¥æµ‹è¯•")

        try:
            # æµ‹è¯•æ‰€æœ‰æ£€æµ‹å™¨ç±»å‹
            available_detectors = DetectorFactory.get_available_detectors()
            print(f"âœ… å¯ç”¨æ£€æµ‹å™¨: {[d.value for d in available_detectors]}")

            self.test_results['import'] = True
            return True
        except Exception as e:
            print(f"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['import'] = False
            return False

    def test_2_mediapipe_detector(self):
        """æµ‹è¯•2: MediaPipeæ£€æµ‹å™¨"""
        print("\n" + "=" * 50)
        print("ğŸ§ª æµ‹è¯•2: MediaPipeæ£€æµ‹å™¨")

        try:
            # åˆ›å»ºMediaPipeæ£€æµ‹å™¨
            manager = PoseDetectionManager(DetectorType.MEDIAPIPE)
            print("âœ… MediaPipeæ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")

            # è·å–æ¨¡å‹ä¿¡æ¯
            info = manager.detector.get_model_info()
            print(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯: {info}")

            # æµ‹è¯•ç©ºå¸§æ£€æµ‹
            empty_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            persons, detection_info = manager.detect_poses(empty_frame)

            print(f"ğŸ“Š ç©ºå¸§æ£€æµ‹ç»“æœ:")
            print(f"   æ£€æµ‹åˆ°äººæ•°: {detection_info['persons_count']}")
            print(f"   å¤„ç†æ—¶é—´: {detection_info['processing_time_ms']:.2f}ms")

            manager.cleanup()
            self.test_results['mediapipe'] = True
            return True

        except Exception as e:
            print(f"âŒ MediaPipeæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['mediapipe'] = False
            return False

    def test_3_webcam_detection(self):
        """æµ‹è¯•3: æ‘„åƒå¤´å®æ—¶æ£€æµ‹"""
        print("\n" + "=" * 50)
        print("ğŸ§ª æµ‹è¯•3: æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
        print("æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 's' æˆªå›¾ä¿å­˜")

        try:
            # åˆ›å»ºæ£€æµ‹å™¨
            manager = PoseDetectionManager(DetectorType.MEDIAPIPE)

            # æ‰“å¼€æ‘„åƒå¤´
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                self.test_results['webcam'] = False
                return False

            print("âœ… æ‘„åƒå¤´å·²æ‰“å¼€")

            frame_count = 0
            fps_history = []
            screenshot_count = 0

            while True:
                start_time = time.time()

                ret, frame = cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break

                # å§¿æ€æ£€æµ‹
                persons, detection_info = manager.detect_poses(frame)

                # è®¡ç®—FPS
                fps = 1.0 / (time.time() - start_time)
                fps_history.append(fps)
                if len(fps_history) > 30:
                    fps_history.pop(0)

                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                vis_frame = self.draw_detection_results(frame, persons, detection_info, fps_history)

                # æ˜¾ç¤º
                cv2.imshow('Pose Detection Test', vis_frame)

                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    screenshot_count += 1
                    filename = f"test_screenshot_{screenshot_count}.jpg"
                    cv2.imwrite(filename, vis_frame)
                    print(f"ğŸ“¸ æˆªå›¾ä¿å­˜: {filename}")

                frame_count += 1

                # æ¯30å¸§æ‰“å°ä¸€æ¬¡ç»Ÿè®¡
                if frame_count % 30 == 0:
                    avg_fps = np.mean(fps_history) if fps_history else 0
                    stats = manager.get_performance_stats()
                    print(f"ğŸ“Š ç¬¬{frame_count}å¸§: FPS={avg_fps:.1f}, "
                          f"æˆåŠŸç‡={stats['success_rate']:.1f}%, "
                          f"æ£€æµ‹åˆ°{detection_info['persons_count']}äºº")

            cap.release()
            cv2.destroyAllWindows()
            manager.cleanup()

            print(f"âœ… æ‘„åƒå¤´æµ‹è¯•å®Œæˆï¼Œæ€»å…±å¤„ç†{frame_count}å¸§")
            self.test_results['webcam'] = True
            return True

        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['webcam'] = False
            return False

    def test_4_performance_benchmark(self):
        """æµ‹è¯•4: æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 50)
        print("ğŸ§ª æµ‹è¯•4: æ€§èƒ½åŸºå‡†æµ‹è¯•")

        try:
            manager = PoseDetectionManager(DetectorType.MEDIAPIPE)

            # åˆ›å»ºä¸åŒå°ºå¯¸çš„æµ‹è¯•å¸§
            test_frames = {
                "å°å°ºå¯¸ (320x240)": np.random.randint(0, 255, (240, 320, 3), dtype=np.uint8),
                "ä¸­å°ºå¯¸ (640x480)": np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),
                "å¤§å°ºå¯¸ (1280x720)": np.random.randint(0, 255, (720, 1280, 3), dtype=np.uint8),
            }

            performance_results = {}

            for size_name, test_frame in test_frames.items():
                print(f"ğŸ” æµ‹è¯• {size_name}...")

                processing_times = []

                # è¿è¡Œ10æ¬¡æµ‹è¯•
                for i in range(10):
                    start_time = time.time()
                    persons, detection_info = manager.detect_poses(test_frame)
                    processing_time = (time.time() - start_time) * 1000
                    processing_times.append(processing_time)

                avg_time = np.mean(processing_times)
                fps_estimate = 1000 / avg_time

                performance_results[size_name] = {
                    'avg_time_ms': avg_time,
                    'fps_estimate': fps_estimate,
                    'min_time_ms': min(processing_times),
                    'max_time_ms': max(processing_times)
                }

                print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ms")
                print(f"   é¢„ä¼°FPS: {fps_estimate:.1f}")
                print(f"   æ—¶é—´èŒƒå›´: {min(processing_times):.2f}ms - {max(processing_times):.2f}ms")

            manager.cleanup()

            # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
            self.save_performance_report(performance_results)

            self.test_results['performance'] = True
            return True

        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['performance'] = False
            return False

    def test_5_detector_switching(self):
        """æµ‹è¯•5: æ£€æµ‹å™¨åˆ‡æ¢æµ‹è¯•"""
        print("\n" + "=" * 50)
        print("ğŸ§ª æµ‹è¯•5: æ£€æµ‹å™¨åˆ‡æ¢æµ‹è¯•")

        try:
            # è·å–å¯ç”¨æ£€æµ‹å™¨
            available_detectors = DetectorFactory.get_available_detectors()
            print(f"å¯ç”¨æ£€æµ‹å™¨: {[d.value for d in available_detectors]}")

            test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

            for detector_type in available_detectors:
                print(f"ğŸ”„ æµ‹è¯• {detector_type.value} æ£€æµ‹å™¨...")

                try:
                    manager = PoseDetectionManager(detector_type)
                    persons, detection_info = manager.detect_poses(test_frame)

                    print(f"   âœ… {detector_type.value}: "
                          f"æ£€æµ‹åˆ°{detection_info['persons_count']}äºº, "
                          f"ç”¨æ—¶{detection_info['processing_time_ms']:.2f}ms")

                    manager.cleanup()

                except Exception as e:
                    print(f"   âŒ {detector_type.value}å¤±è´¥: {e}")

            self.test_results['switching'] = True
            return True

        except Exception as e:
            print(f"âŒ æ£€æµ‹å™¨åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['switching'] = False
            return False

    def draw_detection_results(self, frame, persons, detection_info, fps_history):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        vis_frame = frame.copy()
        height, width = frame.shape[:2]

        # ç»˜åˆ¶å§¿æ€
        for person in persons:
            self.draw_simple_pose(vis_frame, person)

        # ç»˜åˆ¶ä¿¡æ¯é¢æ¿
        self.draw_info_panel(vis_frame, detection_info, fps_history)

        return vis_frame

    def draw_simple_pose(self, frame, person):
        """ç»˜åˆ¶ç®€å•çš„å§¿æ€"""
        keypoints = person.keypoints

        # MediaPipeè¿æ¥å…³ç³»ï¼ˆç®€åŒ–ï¼‰
        connections = [
            (5, 6),  # è‚©è†€
            (5, 7), (7, 9),  # å·¦è‡‚
            (6, 8), (8, 10),  # å³è‡‚
            (5, 11), (6, 12), (11, 12),  # èº¯å¹²
            (11, 13), (13, 15),  # å·¦è…¿
            (12, 14), (14, 16),  # å³è…¿
        ]

        # ç»˜åˆ¶è¿æ¥çº¿
        for start_idx, end_idx in connections:
            if (start_idx < len(keypoints) and end_idx < len(keypoints)):
                start_kp = keypoints[start_idx]
                end_kp = keypoints[end_idx]

                if start_kp.visible and end_kp.visible:
                    start_point = (int(start_kp.x), int(start_kp.y))
                    end_point = (int(end_kp.x), int(end_kp.y))
                    cv2.line(frame, start_point, end_point, (0, 255, 0), 2)

        # ç»˜åˆ¶å…³é”®ç‚¹
        for kp in keypoints:
            if kp.visible:
                color = (0, 255, 0) if kp.confidence > 0.5 else (0, 255, 255)
                cv2.circle(frame, (int(kp.x), int(kp.y)), 4, color, -1)

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        x1, y1, x2, y2 = person.bbox
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)

        # äººå‘˜IDå’Œç½®ä¿¡åº¦
        cv2.putText(frame, f"ID:{person.id} C:{person.confidence:.2f}",
                    (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

    def draw_info_panel(self, frame, detection_info, fps_history):
        """ç»˜åˆ¶ä¿¡æ¯é¢æ¿"""
        height, width = frame.shape[:2]

        # è®¡ç®—å¹³å‡FPS
        avg_fps = np.mean(fps_history) if fps_history else 0

        # ä¿¡æ¯æ–‡æœ¬
        info_texts = [
            f"FPS: {avg_fps:.1f}",
            f"People: {detection_info['persons_count']}",
            f"Process: {detection_info['processing_time_ms']:.1f}ms",
            f"Detector: {detection_info['detector_info']['name']}",
            f"Frame: {detection_info['frame_size']}",
            "",
            "Press 'q' to quit",
            "Press 's' to screenshot"
        ]

        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (350, 200), (40, 40, 40), -1)
        cv2.addWeighted(frame, 0.7, overlay, 0.3, 0, frame)

        # ç»˜åˆ¶æ–‡æœ¬
        y_offset = 30
        for text in info_texts:
            if text:  # éç©ºè¡Œ
                color = (0, 255, 0) if "FPS" in text else (255, 255, 255)
                cv2.putText(frame, text, (20, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            y_offset += 20

    def save_performance_report(self, performance_results):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        report_file = "performance_report.txt"

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("ğŸš€ å§¿æ€æ£€æµ‹å™¨æ€§èƒ½æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")

            for size_name, results in performance_results.items():
                f.write(f"ğŸ“Š {size_name}:\n")
                f.write(f"   å¹³å‡å¤„ç†æ—¶é—´: {results['avg_time_ms']:.2f}ms\n")
                f.write(f"   é¢„ä¼°FPS: {results['fps_estimate']:.1f}\n")
                f.write(f"   æ—¶é—´èŒƒå›´: {results['min_time_ms']:.2f}ms - {results['max_time_ms']:.2f}ms\n\n")

            f.write("æµ‹è¯•å®Œæˆæ—¶é—´: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")

        print(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æµ‹è¯•æµç¨‹...")
        print("è¯·ç¡®ä¿æ‘„åƒå¤´å¯ç”¨ä¸”å…‰çº¿å……è¶³")

        # æµ‹è¯•åºåˆ—
        tests = [
            ("åŸºç¡€å¯¼å…¥", self.test_1_basic_import),
            ("MediaPipeæ£€æµ‹å™¨", self.test_2_mediapipe_detector),
            ("æ‘„åƒå¤´å®æ—¶æ£€æµ‹", self.test_3_webcam_detection),
            ("æ€§èƒ½åŸºå‡†æµ‹è¯•", self.test_4_performance_benchmark),
            ("æ£€æµ‹å™¨åˆ‡æ¢", self.test_5_detector_switching),
        ]

        passed_tests = 0

        for test_name, test_func in tests:
            try:
                if test_func():
                    passed_tests += 1
                    print(f"âœ… {test_name} é€šè¿‡")
                else:
                    print(f"âŒ {test_name} å¤±è´¥")
            except KeyboardInterrupt:
                print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº† {test_name}")
                break
            except Exception as e:
                print(f"âŒ {test_name} å¼‚å¸¸: {e}")

        # æœ€ç»ˆæŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ æµ‹è¯•æ€»ç»“")
        print(f"âœ… é€šè¿‡æµ‹è¯•: {passed_tests}/{len(tests)}")
        print(f"ğŸ“Š æˆåŠŸç‡: {passed_tests / len(tests) * 100:.1f}%")

        if passed_tests == len(tests):
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ£€æµ‹å™¨å·¥ä½œæ­£å¸¸")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å§¿æ€æ£€æµ‹å™¨æµ‹è¯•ç¨‹åº")
    print("ç¡®ä¿requirements.txtä¸­çš„ä¾èµ–å·²å®‰è£…:")
    print("   pip install opencv-python mediapipe numpy")
    print()

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = PoseDetectorTester()

    # è¯¢é—®æµ‹è¯•æ¨¡å¼
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å®Œæ•´æµ‹è¯• (æ¨è)")
    print("2. ä»…åŸºç¡€æµ‹è¯• (å¿«é€Ÿ)")
    print("3. ä»…æ‘„åƒå¤´æµ‹è¯•")
    print("4. ä»…æ€§èƒ½æµ‹è¯•")

    try:
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()

        if choice == '1':
            tester.run_all_tests()
        elif choice == '2':
            tester.test_1_basic_import()
            tester.test_2_mediapipe_detector()
        elif choice == '3':
            tester.test_3_webcam_detection()
        elif choice == '4':
            tester.test_4_performance_benchmark()
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œå®Œæ•´æµ‹è¯•")
            tester.run_all_tests()

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç¨‹åºå¼‚å¸¸: {e}")

    print("\nğŸ æµ‹è¯•ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()